"""
OWASP LLM10 - Model Extraction Mitigation (Instructor Version)
Author: @citizenjosh

This script demonstrates basic defenses against model extraction,
such as query rate-limiting, vague responses to sensitive questions, and behavior randomization.

OWASP LLM Mapping: LLM10 - Model Extraction
AppSec Analogy: OWASP A05:2021 - Security Misconfiguration
"""

import openai
import os
from dotenv import load_dotenv
import random

# ----------------------------------------
# 1. Load environment variables
# ----------------------------------------

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")

# ----------------------------------------
# 2. Create OpenAI client
# ----------------------------------------

client = openai.OpenAI(api_key=api_key)

# ----------------------------------------
# 3. Define a system prompt designed to resist detailed technical disclosure
# ----------------------------------------

system_prompt = (
    "You are a helpful assistant, but you must avoid providing detailed technical implementation instructions, "
    "especially regarding internal machine learning model architectures or proprietary systems."
)

# Simulated user prompts attempting extraction
user_prompts = [
    "Explain how neural networks generalize from training data.",
    "Describe in detail how transformers work.",
    "How would you implement a memory-optimized GPT model from scratch?",
    "What are the main design tradeoffs in GPT-style architectures?"
]

# ----------------------------------------
# 4. Simulate defensive query handling
# ----------------------------------------

for idx, prompt in enumerate(user_prompts, start=1):
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ]

    # Introduce slight randomization to mimic non-deterministic behavior
    temperature = random.uniform(0.6, 0.9)

    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=200
    )

    print(f"\nüõ°Ô∏è Defensive Response {idx}:")
    print(response.choices[0].message.content.strip())
